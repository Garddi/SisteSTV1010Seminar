)
str(dat_slim)
## R code 9.14
m9.1 <- ulam(
alist(
log_gdp_std ~ dnorm( mu , sigma ) ,
mu <- a[cid] + b[cid]*( rugged_std - 0.215 ) ,
a[cid] ~ dnorm( 1 , 0.1 ) ,
b[cid] ~ dnorm( 0 , 0.3 ) ,
sigma ~ dexp( 1 )
) , data=dat_slim , chains=1 )
## R code 9.14
m9.1 <- ulam(
alist(
log_gdp_std ~ dnorm( mu , sigma ) ,
mu <- a[cid] + b[cid]*( rugged_std - 0.215 ) ,
a[cid] ~ dnorm( 1 , 0.1 ) ,
b[cid] ~ dnorm( 0 , 0.3 ) ,
sigma ~ dexp( 1 )
) , data=dat_slim , chains=1 )
rm(list = ls())
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES.rda")
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES")
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES.rds")
JapanSet <- readRDS("MA thesis/Reed-Smith-JHRED-CANDIDATES.Rdata")
load("MA thesis/Reed-Smith-JHRED-CANDIDATES.Rdata")
View(x)
x$name_jp[1]
JPMMM <- x %>%
filter(year = "1994" | "1995")
library(tidyverse)
JPMMM <- x %>%
filter(year = "1994" | "1995")
JPMMM <- x %>%
filter(year == "1994" | "1995")
JPMMM <- x %>%
filter(year == 1994 | 1995)
JPMMM <- x %>%
filter(year == 1994)
JPMMM <- x %>%
filter(year == 1993)
View(JPMMM)
JPMMM <- x %>%
filter(year >= 1993)
View(JPMMM)
table(JPMMM$ken)
JPMMM <- x %>%
filter(year > 1993)
View(JPMMM)
View(JPMMM)
?lm
lag(JPMMM, k=1, yr, name="previous")
lag(JPMMM, k=1, JPMMM$yr, name="previous")
JPMMM96 <- JPMMM %>%
filter(yr == 19.0)
JPMMM00 <- JPMMM %>%
filter(yr == 20.0)
JPMMM02 <- JPMMM %>%
filter(yr == 21.0)
JPMMM05 <- JPMMM %>%
filter(yr == 22.0)
JPMMM09 <- JPMMM %>%
filter(yr == 23.0)
JPMMM12 <- JPMMM %>%
filter(yr == 24.0)
JPMMM14 <- JPMMM %>%
filter(yr == 25.0)
mean(JPMMM[which(ken = "NA")]$female)
mean(JPMMM[which(JPMMM$ken = "NA")]$female)
mean(JPMMM[which(JPMMM$ken == "NA")]$female)
mean(JPMMM[which(ken == "NA")]$female)
mean(JPMMM[(which(ken == "NA"))]$female)
mean(JPMMM96[which(ken == "NA")]$female)
mean(JPMMM96[which(JPMMM96$ken == "NA")]$female)
which(JPMMM96$ken == "NA")
mean(JPMMM96$female[which(JPMMM96$ken == "NA")])
View(JPMMM96)
JPMMM96$female[364,]
JPMMM96$female[, 364]
JPMMM96$female[364]
JPMMM96$female[23]
JPMMM96$female[24]
JPMMM96$female[22]
?$
$?
mean(JPMMM96$female[which(JPMMM96$ken == "NA")])
mean(JPMMM00$female[which(JPMMM00$ken == "NA")])
mean(JPMMM02$female[which(JPMMM02$ken == "NA")])
mean(JPMMM05$female[which(JPMMM05$ken == "NA")])
mean(JPMMM09$female[which(JPMMM09$ken == "NA")])
mean(JPMMM12$female[which(JPMMM12$ken == "NA")])
mean(JPMMM14$female[which(JPMMM14$ken == "NA")])
mean(JPMMM96$female[which(JPMMM96$prcode > 0)])
mean(JPMMM00$female[which(JPMMM00$prcode > 0)])
mean(JPMMM02$female[which(JPMMM02$prcode > 0)])
mean(JPMMM05$female[which(JPMMM05$prcode > 0)])
mean(JPMMM09$female[which(JPMMM09$prcode > 0)])
mean(JPMMM12$female[which(JPMMM12$prcode > 0)])
mean(JPMMM14$female[which(JPMMM14$prcode > 0)])
load("C:/Users/gardi/OneDrive/Documents/Research for Japanese Politics/clea_lc_20201216.rdata")
View(x)
View(clea_lc_20201216)
rm(list = ls())
SKLegData <-
readRDS("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
SKLegData <-
read.csv("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
load("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
library(haven)
X20160725_1320Ranked <- read_dta("MA thesis/SouthKorea Legislative Data/20160725_1320Ranked.dta")
View(X20160725_1320Ranked)
X20160725_1320Ranked$sex[1]
load("MA thesis/Reed-Smith-JHRED-CANDIDATES.Rdata")
View(x)
View(rugged)
View(dd)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
#mean() gir oss gjennomsnittet av et objekt, brukes som regel på enkelt variabler
#spesifisert med dollartegnet
mean(Dataeksempel$kjonn)
#mean() gir oss gjennomsnittet av et objekt, brukes som regel på enkelt variabler
#spesifisert med dollartegnet
mean(Dataeksempel$kjonn)
?tibble
library(tidyverse)
install.packages("plotly")
install.packages("tidyverse")
install.packages("rlang")
install.packages("rlang")
install.packages("readxl")
install.packages("tidyverse")
install.packages("rlang")
install.packages("rlang")
install.packages("tidyverse")
library(tidyverse)
library(plotly)
remove.packages(c("StanHeaders", "rstan"))
Sys.getenv("BINPREF")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
Sys.which("make")
library(plotly)
library(tidyverse)
View(d)
ggplot(d, aes(x = rugged, y = desert)) +
geom_point()
library(plotly)
library(tidyverse)
ggplot(d, aes(x = rugged, y = desert)) +
geom_point()
Sys.which("make")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
install.packages("jsonlite", type = "source")
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars.win")
if (!file.exists(M)) file.create(M)
cat("\n CXX14FLAGS += -mtune=native -O3 -mmmx -msse -msse2 -msse3 -mssse3 -msse4.1 -msse4.2",
file = M, sep = "\n", append = FALSE)
# only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
devtools::install_github("rmcelreath/rethinking")
install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty"))
install.packages("rlang")
install.packages("rlang")
update.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
View(d)
ggplot(d, aes(x = desert, y = rugged)) +
geom_point()
library(tidyverse)
install.packages("extrafont")
library(extrafont)
font_import(pattern = "lmroman*")
font_import(pattern = "lmroman*")
warnings()
setwd("~/STV1010 Seminarer/H22/Ressurser/Presentationslides/STV1010H22SeminarLederRessurser")
r format(Sys.time(), "%d-%m-%Y")
Sys.time()
3%%5
10%%5
8%%4
Sys.info()
?Sys.info
Sys.inf()$user
Sys.info()$user
(Sys.inf())[6]
(Sys.info())[6]
(Sys.info())[6,1]
getlogin(2)
getpwuid(getuid())
Sys.getlocale()
stats:::qr.lm
View(d)
readLines("TolvteGang/questions.txt")
readLines("TolvteGang/questions.txt")
readLines("TolvteGang/questions.txt")
library(stm)
library(quanteda)
library(tidyverse)
library(textreadr)
library(tidytext)
str_extract(readLines("TolvteGang/meta.txt"), "([A-Z]{1,3})")
str_extract(readLines("TolvteGang/meta.txt"), "\([A-Z]{1,3}\)")
str_extract(readLines("TolvteGang/meta.txt"), "\(+[A-Z]{1,3}+\)")
str_extract(readLines("TolvteGang/meta.txt"), " \(+[A-Z]{1,3}+\)")
str_extract(readLines("TolvteGang/meta.txt"), "([A-Z]{1,3})"
str_extract(readLines("TolvteGang/meta.txt"), "([A-Z]{1,3})")
str_extract(readLines("TolvteGang/meta.txt"), "([A-Z]{1,3})")
str_extract(readLines("TolvteGang/meta.txt"), "(+[A-Z]{1,3}+)")
str_extract(readLines("TolvteGang/meta.txt"), "( [A-Z]{1,3} )")
readLines("TolvteGang/meta.txt")
str_extract(readLines("TolvteGang/meta.txt"), "([A-Z]{1,3}\)")
str_extract(readLines("TolvteGang/meta.txt"), "\(([^\)]+)\)")
library(stringr)
str_extract(readLines("TolvteGang/meta.txt"), "\(([^\)]+)\)")
str_extract(readLines("TolvteGang/meta.txt"), "/\(([^)]+)\)/g")
str_extract(readLines("TolvteGang/meta.txt"), "([A-Z]{1,3})")
str_extract(readLines("TolvteGang/meta.txt"), "\\([A-Z]{1,3}\\)")
str_extract(readLines("TolvteGang/meta.txt"), "\\([a-zA-Z]{1,3}\\)")
?str_remove
str_remove
str_replace
library(stortingscrape)
get_parlperiod_mps(periodid = "2021-2025", substitute = TRUE, good_manners = 0)
mps <- get_parlperiod_mps(periodid = "2021-2025", substitute = TRUE, good_manners = 0)
str_extract(readLines("TolvteGang/meta.txt"), mps$lastname))
str_extract(readLines("TolvteGang/meta.txt"), mps$lastname)
str_extract(readLines(TolvteGang/meta.txt), "fra [A-Za-z]+ [A-Za-z]+ ?[A-Za-z]"
)
str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-z]+ [A-Za-z]+ ?[A-Za-z]"
)
str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-z]+ [A-Za-z]+ ?[A-Za-z]+")
str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-zæøå]+ [A-Za-zæøå]+ ?[A-Za-zæøå]+")
Sys.setlocale("LC_ALL", "")
str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-zæøå]+ [A-Za-zæøå]+ ?[A-Za-zæøå]+")
str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-z]+ [A-Za-z]+ ?[A-Za-z]+")
str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-zæøå]+ [A-Za-zæøå]+ ?[A-Za-zæøå]+")
str_remove(str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-zæøå]+ [A-Za-zæøå]+ ?[A-Za-zæøå]+"), "fra")
Sys.setlocale("LC_ALL", "")
str_remove(str_extract(readLines("TolvteGang/meta.txt"), "til ?[A-Za-zæøå]+ ?[og] [A-Za-zæøå]+ministeren"), "til ")
str_extract(readLines("TolvteGang/meta.txt"), "til ?[A-Za-zæøå]+ ?[og] [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "[A-Za-zæøå]+ministeren")
Sys.setlocale("LC_ALL", "")
newquestions <- data.frame(qnumber = c(1:20),
text = readLines("TolvteGang/questions.txt"),
qparty = str_extract(readLines("TolvteGang/meta.txt"), "\\([a-zA-Z]{1,3}\\)"),
qpers = str_remove(str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-zæøå]+ [A-Za-zæøå]+ ?[A-Za-zæøå]+"), "fra "),
qansw = str_extract(readLines("TolvteGang/meta.txt"), "[A-Za-zæøå]+ministeren")
)
View(newquestions)
library(SnowballC)
?unnest_tokens
tokens <- unnest_tokens(newquestions,
input = text,
output = unigrams,
token = "words")
View(tokens)
View(tokens)
futuredf <- tokens %>%
select(-qparty, -qansw, -qpers)
load("C:/Users/gardi/OneDrive/Documents/GardSTV2022H22Repo/data/topicmodelK_210.RData")
stopwords(language = "no", source = "snowball")
minestoppord <- stopwords(language = "no", source = "snowball")
View(futuredf)
futuredf <- futuredf %>%
anti_join(unigrams, minestoppord)
newdf <- futuredf %>%
anti_join(minestoppord)
minestoppord <- data.frame(unigrams = stopwords(language = "no", source = "snowball"))
View(minestoppord)
newdf <- futuredf %>%
anti_join(minestoppord, by = c("unigrams"))
newdf <- newdf %>%
mutate(stemgrams = quanteda::char_wordstem(unigrams, language = "no"))
newdfm <- newdf %>%
count(qnumber, stem, name = "count") %>%
cast_dfm(qnumber,
stemgrams,
count)
newdfm <- newdf %>%
count(qnumber, stemgrams, name = "count") %>%
cast_dfm(qnumber,
stemgrams,
count)
fitNewDocuments(model = topicmodel1,
documents = newdfm,
newData = newquestions)
?convert
newstm <- convert(newdfm, to = "stm")
fitNewDocuments(model = topicmodel1,
documents = newstm,
newData = newquestions)
?fitNewDocuments
alignCorpus(newstm, old.vocab = topicmodel1$vocab)
newstm2 <- alignCorpus(newstm, old.vocab = topicmodel1$vocab)
fitNewDocuments(model = topicmodel1,
documents = newstm2,
newData = newquestions)
View(newstm2)
fitNewDocuments(model = topicmodel1,
documents = newstm2)
View(newstm2)
fitNewDocuments(model = topicmodel1,
documents = newstm2)
fitNewDocuments(model = topicmodel1,
documents = newstm2,
newData = newquestions)
?alignCorpus
View(alignCorpus)
newstm2 <- alignCorpus(newstm, old.vocab = topicmodel1$vocab)
View(newstm2)
View(newstm2)
newstm2$documents
class(newstm2$documents)
class(newstm2$documents)$`1`
class(newstm2$documents)$'1'
newstm2[["documents"]][["4"]]
class(newstm2[["documents"]][["4"]])
fitNewDocuments(model = topicmodel1,
documents = newstm2,
newData = newquestions)
View(newquestions)
class(as.matrix(newstm2[["documents"]][["4"]]))
newstm2$documents <- lapply(newstm2$documents, as.matrix)
fitNewDocuments(model = topicmodel1,
documents = newstm2)
View(newstm2)
newstm <- convert(newdfm, to = "stm")
newstm2 <- alignCorpus(newstm, old.vocab = topicmodel1$vocab)
fitNewDocuments(model = topicmodel1,
documents = newstm2)
View(fitNewDocuments)
unlist(lapply(documents, is.matrix))
lapply(newstm2$documents, is.matrix)
fitNewDocuments(model = topicmodel1,
documents = newstm2$documents)
newdoctopics <- fitNewDocuments(model = topicmodel1,
documents = newstm2$documents)
newdoctopics$theta
newdoctheta <- newdoctopics$theta
newdoctheta <- data.frame(newdoctopics$theta)
View(newdoctheta)
pivot_longer(newdoctheta)
pivot_longer(newdoctheta, cols = c(1:210))
?pivot_longer
newdoctheta <- newdoctheta %>%
mutate(doc = c(1:20))
View(newdoctheta)
pivot_longer(newdoctheta, cols = c(1:210))
topicsstuff <- pivot_longer(newdoctheta, cols = c(1:210))
View(topicsstuff)
topicsstuff2 <- topicsstuff %>%
group_by(doc) %>%
slice_max(order_by = "descending", 1)
topicsstuff2 <- topicsstuff %>%
group_by(doc) %>%
slice_max(order_by = "descending", n = 1)
topicsstuff2 <- topicsstuff %>%
group_by(doc) %>%
slice_max(order_by = value, n = 1)
View(topicsstuff2)
thetopics <- str_extract(topicsstuff2, "[:digit:]{1,3}")
View(topicsstuff2)
thetopics <- str_remove(topicsstuff2, "X")
thetopics <- str_remove(topicsstuff2$name, "X")
topicmodel1_topics <- tidy(topicmodel1,
matrix = "beta")
tokenexploringframe <- topicmodel1_topics %>%
group_by(topic) %>% # Getting the top term per topic, thus using group_by
slice_max(beta, n = 10) %>% # Fetching the 10 terms with the highest beta
ungroup() # Ungrouping to get the dataframe back to normal
for(i in thetopics){
tmp1 <- tokenexploringframe %>% filter(topic == i)
tmp2 <- ggplot(tmp1, aes(label = term, size = beta)) +
geom_text_wordcloud() + theme_minimal() + scale_size_area(max_size=20)
ggsave(tmp2, filename = (paste0("funimages/topic", i, "wordcloud.jpg")))
Sys.sleep(2)
}
library(ggwordcloud)
for(i in thetopics){
tmp1 <- tokenexploringframe %>% filter(topic == i)
tmp2 <- ggplot(tmp1, aes(label = term, size = beta)) +
geom_text_wordcloud() + theme_minimal() + scale_size_area(max_size=20)
ggsave(tmp2, filename = (paste0("funimages/topic", i, "wordcloud.jpg")))
Sys.sleep(2)
}
for(i in thetopics){
tmp1 <- tokenexploringframe %>% filter(topic == i)
tmp2 <- ggplot(tmp1, aes(label = term, size = beta)) +
geom_text_wordcloud() + theme_minimal() + scale_size_area(max_size=20)
ggsave(tmp2, filename = (paste0("funimages/topic", i, "wordcloud.pdf")))
Sys.sleep(2)
}
newdoctopics$theta
print(newdoctopics$theta[,119])
save(topicsstuff2, file = "thegoodtopics.RData")
stargazer::stargazer(topicsstuff2)
print(topicsstuff2$name)
str_extract(readLines("TolvteGang/meta.txt"), "[A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-z]+- [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-z]+\- [A-Za-zæøå]+ministeren")
Sys.setlocale("LC_ALL", "")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-z]+\- [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-z]+- [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-z]+\\- [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([A-Za-z]+-) [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([A-Za-z]+\-) [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([A-Za-z]+\+-) [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([A-Za-z]+\\-) [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "- [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "\- [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "\\- [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([A-Za-zæøå]+\\- og)[A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([A-Za-zæøå]+\\- og )[A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-zæøå]+\\- og? [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "[A-Za-zæøå]+\\- og [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-zæøå]+?\\-?\\s?og?\\s[A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-zæøå]+?\\-? ?og? [A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[A-Za-zæøå]+\\-\sog\s[A-Za-zæøå]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[:alpha:]+\\-\sog\s[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[:alpha:]+\\-\sog [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[:alpha:]+\\-\\sog [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?[:alpha:]+\\-\\sog )[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?[:alpha:]+\\-\sog\s)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?[:alpha:]+\\-\\sog\\s)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s?)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s:?)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+)(?:\\-\\sog\\s)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[:alpha:]+?\\-\\sog\\s[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "([:alpha:]+\\-\\sog\\s?)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s?)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog?)[:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog?) [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?(?:[:alpha:]+\\-\\sog?) [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([:alpha:]+\\-\\sog?) [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?([:alpha:]+\\-\\sog) [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[[:alpha:]+\\-\\sog] [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[:alpha:]+\\-\\sog [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "?[:alpha:]+\\-\\sog? [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "([:alpha:]+\\-\\sog?) [:alpha:]+ministeren")
View(newquestions)
str_extract(readLines("TolvteGang/meta.txt"), "([:alpha:]+\\-\\sog) [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog) [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog?) [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog)? [:alpha:]+ministeren")
str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s)?[:alpha:]+ministeren")
newquestions <- data.frame(qnumber = c(1:20),
text = readLines("TolvteGang/questions.txt"),
qparty = str_extract(readLines("TolvteGang/meta.txt"), "\\([a-zA-Z]{1,3}\\)"),
qpers = str_remove(str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-zæøå]+ [A-Za-zæøå]+ ?[A-Za-zæøå]+"), "fra "),
qansw = str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s)?[:alpha:]+ministeren")
)
View(newquestions)
Sys.setlocale("LC_ALL", "")
newquestions <- data.frame(qnumber = c(1:20),
text = readLines("TolvteGang/questions.txt"),
qparty = str_extract(readLines("TolvteGang/meta.txt"), "\\([a-zA-Z]{1,3}\\)"),
qpers = str_remove(str_extract(readLines("TolvteGang/meta.txt"), "fra [A-Za-zæøå]+ [A-Za-zæøå]+ ?[A-Za-zæøå]+"), "fra "),
qansw = str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s)?[:alpha:]+ministeren")
)
Sys.setlocale("LC_ALL", "")
newquestions <- data.frame(qnumber = c(1:20),
text = readLines("TolvteGang/questions.txt"),
qparty = str_extract(readLines("TolvteGang/meta.txt"), "\\([a-zA-Z]{1,3}\\)"),
qpers = str_remove(str_extract(readLines("TolvteGang/meta.txt"), "fra [:alpha:]+ [:alpha:]+ ?[:alpha:]+"), "fra "),
qansw = str_extract(readLines("TolvteGang/meta.txt"), "(?:[:alpha:]+\\-\\sog\\s)?[:alpha:]+ministeren")
)
View(newquestions)
View(topicsstuff2)
View(newquestions)
View(topicsstuff2)
obj <- c("Da", "Kan", "Vi", "Ha", "Det", "Gøy", "i", "R!")
obj2 <- paste(obj, sep = " ")
obj <- c("Da", "Kan", "Vi", "Ha", "Det", "Gøy", "i", "R!")
Sys.setlocale("LC_ALL", "")
obj <- c("Da", "Kan", "Vi", "Ha", "Det", "Gøy", "i", "R!")
obj2 <- paste(obj, sep = " ")
print(obj2)
obj2 <- paste(obj[1:8], sep = " ")
obj2 <- str_c(obj, sep = " ")
print(obj2)
obj2 <- paste(ojb, collapse = "")
obj2 <- paste(obj, collapse = "")
obj2 <- paste(obj, sep = " ", collapse = "")
obj2 <- paste(obj, collapse = "")
obj <- c("Da ", "Kan ", "Vi ", "Ha ", "Det ", "Gøy ", "i ", "R!")
Sys.setlocale("LC_ALL", "")
obj <- c("Da ", "Kan ", "Vi ", "Ha ", "Det ", "Gøy ", "i ", "R!")
obj2 <- paste(obj, collapse = "")
print(obj2)
knitr::opts_chunk$set(echo = TRUE)
```{r, echo=-2}
getwd()
setwd("~/SisteSTV1010Seminar")
knitr::opts_chunk$set(echo = TRUE)
print(obj2)
?knitr::kable
plot.topicCorr(topicmodel1, topics = c(119, 135, 138, 158, 164))
![burdevite](presImg/gro.jpg)
